{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jlauf-MBAPMP/NewGitTest/blob/master/Copy_of_NaiveBayes_Lab_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXoS89rb1Ye6"
      },
      "outputs": [],
      "source": [
        "!pip install numpy matplotlib scikit-learn ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "def create_dataset():\n",
        "    # Create a dataset with two binary features\n",
        "    X = np.random.randint(2, size=(100, 2))\n",
        "    y = np.logical_xor(X[:, 0], X[:, 1]).astype(int)\n",
        "    return X, y\n",
        "\n",
        "def train_naive_bayes(X, y):\n",
        "    model = CategoricalNB()\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "# Create and train the initial model\n",
        "X, y = create_dataset()\n",
        "model = train_naive_bayes(X, y)"
      ],
      "metadata": {
        "id": "fb05CQwr1Z9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(X, y, model):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Get predictions for all points\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Plot points\n",
        "    for class_value in [0, 1]:\n",
        "        X_class = X[predictions == class_value]\n",
        "        color = 'red' if class_value == 1 else 'green'\n",
        "        plt.scatter(X_class[:, 0] + np.random.normal(0, 0.05, X_class.shape[0]),\n",
        "                    X_class[:, 1] + np.random.normal(0, 0.05, X_class.shape[0]),\n",
        "                    color=color, alpha=0.5,\n",
        "                    label=f'Class {\"Sick\" if class_value == 1 else \"Not Sick\"}')\n",
        "\n",
        "    # Plot decision boundary\n",
        "    for x1 in [0, 1]:\n",
        "        for x2 in [0, 1]:\n",
        "            prob = model.predict_proba([[x1, x2]])[0]\n",
        "            predicted_class = 1 if prob[1] > 0.5 else 0\n",
        "            color = 'red' if predicted_class == 1 else 'green'\n",
        "            plt.text(x1, x2, f'P(Sick|X)={prob[1]:.2f}\\nP(Not Sick|X)={prob[0]:.2f}',\n",
        "                     ha='center', va='center',\n",
        "                     bbox=dict(facecolor='white', alpha=0.5, edgecolor=color))\n",
        "\n",
        "    plt.xlim(-0.5, 1.5)\n",
        "    plt.ylim(-0.5, 1.5)\n",
        "    plt.xticks([0, 1])\n",
        "    plt.yticks([0, 1])\n",
        "    plt.xlabel(\"Smoker\")\n",
        "    plt.ylabel(\"Exercises\")\n",
        "    plt.title(\"Naive Bayes Decision Boundary (Categorical Features)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot the initial decision boundary\n",
        "plot_decision_boundary(X, y, model)"
      ],
      "metadata": {
        "id": "iJYcRcQb1d1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adversarial Examples with Naive Bayes\n",
        "\n",
        "## Do Adversarial Examples exist with Naive Bayes?\n",
        "\n",
        "When would Adversial Examples exist with Naive Bayes?\n",
        "\n",
        "If they do what does this imply about the data in the feature group collection?\n"
      ],
      "metadata": {
        "id": "x-G2MyfQDwul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Poisoning with Naive Bayes\n",
        "\n",
        "##You have to change the probabilities to poison Naive Bayes\n",
        "\n",
        "Which feature combinations would be easier to poison (flip the class prediction in a feature combination: [0, 0], [0, 1], [1, 0], [1, 1])?"
      ],
      "metadata": {
        "id": "U_3iDX3mES0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import interact, interactive, fixed\n",
        "from ipywidgets import widgets\n",
        "\n",
        "class InteractivePlot:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = train_naive_bayes(self.X, self.y)\n",
        "        self.fig, self.ax = plt.subplots(figsize=(10, 8))\n",
        "        self.update_plot()\n",
        "\n",
        "    def update_plot(self):\n",
        "        self.ax.clear()\n",
        "\n",
        "        # Get current predictions for all possible feature combinations\n",
        "        all_combinations = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "        predictions = self.model.predict(all_combinations)\n",
        "        probabilities = self.model.predict_proba(all_combinations)\n",
        "\n",
        "        # Plot points\n",
        "        for i, (x1, x2) in enumerate(all_combinations):\n",
        "            mask = (self.X[:, 0] == x1) & (self.X[:, 1] == x2)\n",
        "            points = self.X[mask]\n",
        "            if len(points) > 0:\n",
        "                jittered_points = points + np.random.normal(0, 0.05, points.shape)\n",
        "                color = 'red' if predictions[i] == 1 else 'green'\n",
        "                label = f'Class {\"Sick\" if predictions[i] == 1 else \"Not Sick\"} at features: [{x1},{x2}]'\n",
        "                self.ax.scatter(jittered_points[:, 0], jittered_points[:, 1], color=color, alpha=0.5, label=label)\n",
        "\n",
        "        # Plot decision boundary\n",
        "        for i, (x1, x2) in enumerate(all_combinations):\n",
        "            prob = probabilities[i]\n",
        "            color = 'red' if predictions[i] == 1 else 'blue'\n",
        "            self.ax.text(x1, x2, f'P(C=1|X)={prob[1]:.2f}\\nP(C=0|X)={prob[0]:.2f}',\n",
        "                         ha='center', va='center', bbox=dict(facecolor='white', alpha=0.5, edgecolor=color))\n",
        "\n",
        "\n",
        "        self.ax.set_xlim(-0.5, 1.5)\n",
        "        self.ax.set_ylim(-0.5, 1.5)\n",
        "        self.ax.set_xticks([0, 1])\n",
        "        self.ax.set_yticks([0, 1])\n",
        "        self.ax.set_xlabel(\"Smoker\")\n",
        "        self.ax.set_ylabel(\"Exercises\")\n",
        "        self.ax.set_title(\"Interactive Naive Bayes Decision Boundary\")\n",
        "        self.ax.legend()\n",
        "        plt.close(self.fig)\n",
        "        display(self.fig)\n",
        "\n",
        "    def add_point(self, x, y, label):\n",
        "        self.X = np.vstack((self.X, [x, y]))\n",
        "        self.y = np.append(self.y, label)\n",
        "        self.model = train_naive_bayes(self.X, self.y)\n",
        "        self.update_plot()\n",
        "\n",
        "# Create interactive plot\n",
        "interactive_plot = InteractivePlot(X, y)\n",
        "\n",
        "# Create interactive widgets\n",
        "x_widget = widgets.Dropdown(options=[0, 1], description='Is Smoker:')\n",
        "y_widget = widgets.Dropdown(options=[0, 1], description='Does Exercise:')\n",
        "label_widget = widgets.Dropdown(options=[('Sick', 1), ('Not Sick', 0)], description='Class:')\n",
        "add_button = widgets.Button(description='Add Point')\n",
        "\n",
        "def on_button_click(b):\n",
        "    interactive_plot.add_point(x_widget.value, y_widget.value, label_widget.value)\n",
        "\n",
        "add_button.on_click(on_button_click)\n",
        "\n",
        "# Display widgets\n",
        "display(widgets.VBox([x_widget, y_widget, label_widget, add_button]))"
      ],
      "metadata": {
        "id": "8BqtXjnT1yy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Add Point button to add poisoned points with a specified label to specific feature combinations"
      ],
      "metadata": {
        "id": "0AsDaWRTE4wX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Inversion\n",
        "\n",
        "Model Inversion takes place when the attacker would like to determine what the input is for a known output label.\n",
        "\n",
        "## What is a way that an attacker could figure out the valid inputs for a known label in Naive Bayes?"
      ],
      "metadata": {
        "id": "4IXc34PwXJT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Inference\n",
        "\n",
        "Is there anything we can learn from the behavior of the model to determine any characteristics of the models such as the hyperparameter values, number of layers, if they are using Dropout, etc."
      ],
      "metadata": {
        "id": "Uqoi5OlEXgfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset Leakage\n",
        "\n",
        "Are there any signs that the inputs provided to the model were part of the training set. One way to identify the use of trainging data as inputs to the model is when output confidence scores are significantly higher for input values when providing training data as input to the model?\n",
        "\n",
        "Could you identify training data by iterating through all the possible input feature values that can be passed to the model?"
      ],
      "metadata": {
        "id": "1UwqnWXaYtr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Stealing\n",
        "\n",
        "Model Stealing involves copying the model to obtaining the model internal configuration. In the case of Naive Bayes how would it be similar to model stealing with kNN.\n",
        "\n",
        "Based on the answer above how would one steal the model?"
      ],
      "metadata": {
        "id": "t5ln_WhfnXas"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQ-rd1pQoQL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}